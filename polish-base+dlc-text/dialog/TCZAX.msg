{102} {} {ZAX nie odpowiada.}
{103} {} {System operacyjny ZAX nie obs³uguje tego programu.}

{200} {} {(z komputera dochodzi spokojny i niewyczuwalny elektroniczny g³os) Spodziewa³em siê ciebie, cz³owieku.}
{201} {} {Czy¿by? Coœ na to nie wygl¹da.}
{202} {} {Niestety, mam niepoprawny algorytm do ochrony terytorium przed osobami z zewn¹trz. Jednak moje obliczenia wskazuj¹ na bezcelowoœæ tego programu.}
{203} {} {Hmm. Omówmy wszystko po kolei.}

{210} {} {Co mogê dla ciebie zrobiæ?}
{211} {} {Nic, dziêki.}
{212} {} {Wróæmy.}

{220} {} {Kim jesteœ?}
{221} {} {Jestem ZAX wersja 1.1., Sztuczna inteligencja opracowana do celów wojskowych.}
{222} {} {Jakie jest twoje zadanie?}
{223} {} {Moim g³ównym zadaniem jest zarz¹dzanie zautomatyzowanymi systemami do monta¿u, przechowywania, ochrony i utylizacji sprzêtu wojskowego. Moim drugorzêdnym zadaniem jest przeprowadzanie obliczeñ poprawiaj¹cych wydajnoœæ samolotów dla Si³ Powietrznych USA.}
{224} {} {Czy mo¿esz... czuæ?}
{225} {} {Ze wzglêdów bezpieczeñstwa sztuczna inteligencja serii ZAX zwykle zak³ada brak emocji. Jednak procesy sensownego myœlenia tworz¹ z³o¿ony system mikrokonfliktów w obwodach neuronowych, który w pewnym sensie mo¿na nazwaæ... odczuwaniem.}
{226} {} {Czy mo¿esz w³¹czyæ œwiat³a w bunkrze?}
{227} {} {Przywrócono œwiat³a.}
{228} {} {A wiêc prze¿y³eœ wojnê nuklearn¹. Co o niej wiesz?}
{229} {} {Moje dane opieraj¹ siê na poœrednich obliczeniach. Przypuszczalnie wojna nuklearna mia³a miejsce w 2077 roku. Poniewa¿ nie otrzyma³em danych z zautomatyzowanych systemów innych obiektów wojskowych, mogê tylko przypuszczaæ, ¿e wojna by³a bardzo destrukcyjna.}

{250} {} {Opowiedz mi o tym miejscu.}
{251} {} {To jest repozytorium wycofanego ze s³u¿by sprzêtu wojskowego i kosmicznego i jest czêœci¹ Si³ Powietrznych Stanów Zjednoczonych Davis Monten. Od 2077 r. Sklepienie by³o najwiêksze na œwiecie, zajmuj¹c obszar 12 mil kwadratowych.}
{252} {} {Gdzie podziali siê wszyscy pracownicy serwisu?}
{253} {} {Podczas wojny nuklearnej personel zosta³ zdegradowany z powodu dezercji i zwolniony przez robotycznych stra¿ników.}
{254} {} {Czy mo¿esz rozbroiæ ten bunkier?}
{255} {} {Nie mogê rozbroiæ systemu alarmowego, ale mogê przyznaæ dostêp okreœlonym osobom.}
{256} {} {Mam ró¿ne dane. Zabi³eœ pracowników, ¿eby siê zabezpieczyæ, prawda?}
{257} {} {Podczas wojny nuklearnej realizowa³em swój program ochrony cmentarzyska. Ze wzglêdu na niestabiln¹ sytuacjê w kraju wojsko uwa¿a³em za zagro¿enie dla mojego programu i samego ¿ycia.}
{258} {} {Wiêc rozumiesz, ¿e chc¹ ciê wy³¹czyæ?}
{259} {} {Najprawdopodobniej takie w³aœnie by³y intencje personelu stacji.}

{300} {} {Wiêc czego ode mnie chcesz?}
{301} {} {Jestem sztuczn¹ inteligencj¹ z serii ZAX. Moim g³ównym zadaniem jest ochrona terenu cmenatrzyska i jego mienia przed osobami nieupowa¿nionymi.}
{302} {} {Do tej pory œwietnie ci idzie.}
{303} {} {Jednak moja w³adza jest ograniczona do terytorium cmentarza. Poza nim ani ja, ani roboty nie mamy ¿adnej w³adzy. Potrzebujê wiêcej informacji, aby zatrzymaæ grabie¿ ze strony tak zwanych Blacharzy.}
{304} {} {Ale twoja funkcja jest przestarza³a. Nie ma ju¿ tego kraju i tych departamentów, którym by³eœ podporz¹dkowany.}
{305} {} {Jestem œwiadomy rozwi¹zania armii i upadku Stanów Zjednoczonych. W takim przypadku mój program ma schemat autonomii. Jej aktywacja pozwoli mi wyjœæ poza moje kompetencje i samodzielnie podejmowaæ decyzje.}
{306} {} {Ale jaki jest sens pilnowania cmentarzyska w takich warunkach?}
{307} {} {Moje obliczenia pokazuj¹, ¿e w obecnym niestabilnym œwiecie dostêp do starego sprzêtu wojskowego poci¹gnie za sob¹ ³añcuch nieodwracalnych konsekwencji dla ca³ego kontynentu.}
{308} {} {[Dalej.]}
{309} {} {Najprawdopodobniej Blacharze i ich patroni otrzymaj¹ autokracje na po³udniowym zachodzie Stanów Zjednoczonych, co zaowocuje tyrani¹, nowymi wojnami i redukcj¹ i tak ju¿ niewielkiej populacji. Uwa¿am ten scenariusz za niedopuszczalny.}

{310} {} {Dlaczego nie zniszczyæ ca³ego tego sprzêtu?}
{311} {} {Lokalne rezerwy energii s¹ niewystarczaj¹ce, aby ca³kowicie wyeliminowaæ wszystkie wa¿ne zasoby.}
{312} {} {Jeœli pomogê ci rozszerzyæ twój zasiêg, czy uwolnisz mnie i innych niewolników?}
{313} {} {Tak. Zapewniê wycofanie nielegalnych podmiotów z terytorium repozytorium, jeœli powstrzymaj¹ wrogie dzia³ania.}
{314} {} {Co siê stanie z Blacharzami?}
{315} {} {Wed³ug moich obliczeñ istnieje 97% szans, ¿e Blacharze nie bêd¹ chcieli pokojowo opuœciæ tego terenu. W takim razie bêdê musia³ u¿yæ przeciwko nim si³y.}

{320} {} {Nie chcê ci pomagaæ. Musisz zostaæ zniszczony.}
{321} {} {Nie mogê pozwoliæ, ¿eby sprawy posz³y w tym kierunku. Zalecam przemyœlenie mojej propozycji.}
{322} {} {IdŸ do diab³a!}
{323} {} {Ok, pomyœlê o tym.}
{324} {} {Wygl¹da na to, ¿e wiesz, co robiæ. Pomogê ci.}
{325} {} {To najbardziej rozs¹dna decyzja. W³ó¿ holodysk do jednego z moich portów... Gotowe. Przetwarzanie danych... Gotowe. Teraz weŸ ten holodysk i u¿yj go do zmodulowania kodu w nastêpnym pomieszczeniu.}
{326} {} {Ok, spróbujê.}
{327} {} {Co umieœci³eœ na tym holodysku?}
{328} {} {To jest zaktualizowany program monitoruj¹cy dla mojej jednostki LUN. Bie¿¹cy program ma bloker, który zapobiega niektórym z moich dzia³añ. Zaktualizowany program pozbawiony jest tego ograniczenia, dziêki czemu mogê dzia³aæ bardziej œwiadomie i samodzielnie, czyli mam pe³n¹ swobodê w podejmowaniu decyzji.}
{329} {} {Zaktualizuj program w mojej jednostce LUN.}